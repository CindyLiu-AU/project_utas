{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D, Dropout, Activation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VvXOu32XOMIz"
   },
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv('BBB_planA_weekly.csv')\n",
    "df = df_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "      <th>T21</th>\n",
       "      <th>T22</th>\n",
       "      <th>T23</th>\n",
       "      <th>T24</th>\n",
       "      <th>T25</th>\n",
       "      <th>T26</th>\n",
       "      <th>T27</th>\n",
       "      <th>T28</th>\n",
       "      <th>T29</th>\n",
       "      <th>T30</th>\n",
       "      <th>T31</th>\n",
       "      <th>T32</th>\n",
       "      <th>T33</th>\n",
       "      <th>T34</th>\n",
       "      <th>T35</th>\n",
       "      <th>T36</th>\n",
       "      <th>T37</th>\n",
       "      <th>T38</th>\n",
       "      <th>T39</th>\n",
       "      <th>id1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>117.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>1</td>\n",
       "      <td>562.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      final_result     T0     T1    T2     T3    T4     T5     T6     T7  \\\n",
       "0                1   13.0    0.0   0.0   38.0   0.0    0.0    0.0   48.0   \n",
       "1                1    7.0   25.0   6.0    1.0  10.0   16.0    4.0    2.0   \n",
       "2                0   71.0   96.0   3.0  117.0  83.0  218.0  303.0    1.0   \n",
       "3                1  117.0   21.0  36.0    3.0   1.0   24.0  120.0    0.0   \n",
       "4                0    2.0    1.0   0.0    8.0   0.0    0.0    4.0    0.0   \n",
       "...            ...    ...    ...   ...    ...   ...    ...    ...    ...   \n",
       "5336             1   64.0   28.0  29.0   21.0   9.0   25.0    0.0   42.0   \n",
       "5337             0   32.0   14.0   7.0   38.0  15.0   84.0   43.0   32.0   \n",
       "5338             1  562.0  272.0  62.0  149.0  73.0  265.0  142.0  107.0   \n",
       "5339             0    0.0   14.0   0.0   13.0   0.0    0.0   29.0    0.0   \n",
       "5340             1    0.0    1.0  21.0   31.0  48.0    0.0   10.0   49.0   \n",
       "\n",
       "         T8     T9    T10    T11    T12   T13    T14    T15    T16    T17  \\\n",
       "0      40.0    0.0    0.0   14.0    0.0   0.0  126.0    0.0    0.0    0.0   \n",
       "1       0.0    1.0    5.0    0.0    0.0   1.0   12.0   14.0   45.0   23.0   \n",
       "2      18.0   23.0    5.0    0.0    4.0  10.0  112.0    0.0    4.0   23.0   \n",
       "3      50.0   54.0    0.0   23.0   47.0  35.0  106.0   91.0   35.0   12.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...   ...    ...    ...    ...    ...   \n",
       "5336    3.0    0.0   25.0    0.0   34.0  16.0   35.0   21.0   15.0    1.0   \n",
       "5337    0.0    0.0   15.0    1.0    2.0  63.0    0.0   15.0    3.0   16.0   \n",
       "5338  279.0  197.0  217.0  195.0  179.0  68.0  221.0  134.0  278.0  207.0   \n",
       "5339    0.0    0.0    0.0    3.0   67.0   5.0    0.0    1.0    0.0    0.0   \n",
       "5340   33.0    0.0    0.0   40.0   20.0  17.0  161.0   78.0    0.0    6.0   \n",
       "\n",
       "       T18    T19    T20    T21    T22    T23    T24   T25    T26    T27  \\\n",
       "0      0.0   63.0    4.0    0.0    0.0    0.0  118.0   0.0    6.0    3.0   \n",
       "1     40.0   13.0    0.0    0.0    0.0   14.0    0.0   0.0    0.0    0.0   \n",
       "2      0.0   86.0    1.0  125.0   46.0   53.0    0.0  15.0   40.0   33.0   \n",
       "3     73.0   12.0  204.0   92.0  102.0   23.0   71.0  99.0   12.0  225.0   \n",
       "4      0.0    0.0    0.0    1.0    0.0    0.0    0.0   0.0    0.0    0.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
       "5336   6.0   41.0    0.0    0.0   14.0    0.0   21.0  15.0   31.0    0.0   \n",
       "5337   4.0    3.0    8.0    4.0   17.0   14.0   42.0   2.0    0.0   14.0   \n",
       "5338  55.0   68.0   55.0   40.0  211.0  251.0   72.0  34.0   29.0  129.0   \n",
       "5339   0.0    0.0    9.0    0.0    0.0   50.0    0.0   0.0   14.0    0.0   \n",
       "5340  48.0  173.0   44.0   32.0   60.0  143.0  131.0  38.0  114.0   95.0   \n",
       "\n",
       "        T28   T29    T30   T31   T32    T33   T34    T35   T36  T37  T38  T39  \\\n",
       "0       0.0   0.0  149.0   0.0   0.0    0.0  83.0   33.0   0.0  0.0  1.0  0.0   \n",
       "1       2.0  60.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0  0.0  0.0  0.0   \n",
       "2      17.0  72.0   35.0   0.0   0.0    0.0  59.0    3.0   3.0  5.0  4.0  0.0   \n",
       "3     149.0   4.0   19.0  17.0  67.0    0.0  54.0    0.0   0.0  0.0  0.0  0.0   \n",
       "4       0.0   0.0    0.0   0.0   0.0    0.0   0.0    0.0   0.0  0.0  0.0  0.0   \n",
       "...     ...   ...    ...   ...   ...    ...   ...    ...   ...  ...  ...  ...   \n",
       "5336    2.0  14.0   30.0   1.0   8.0   78.0   0.0    2.0   0.0  0.0  0.0  0.0   \n",
       "5337    1.0   1.0    7.0   0.0   0.0   56.0   0.0    0.0   0.0  0.0  0.0  0.0   \n",
       "5338   64.0  21.0    0.0  44.0  48.0  103.0   4.0    7.0   0.0  0.0  0.0  0.0   \n",
       "5339    8.0   5.0    4.0  31.0  11.0    1.0   0.0    0.0   0.0  0.0  0.0  0.0   \n",
       "5340   88.0  26.0   84.0  58.0  16.0   46.0  85.0  160.0  22.0  9.0  6.0  0.0   \n",
       "\n",
       "       id1  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  \n",
       "...    ...  \n",
       "5336  5336  \n",
       "5337  5337  \n",
       "5338  5338  \n",
       "5339  5339  \n",
       "5340  5340  \n",
       "\n",
       "[5341 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "xS2B1k_Pich7",
    "outputId": "af18988d-e764-4505-9dbe-af7cf825edae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "      <th>T21</th>\n",
       "      <th>T22</th>\n",
       "      <th>T23</th>\n",
       "      <th>T24</th>\n",
       "      <th>T25</th>\n",
       "      <th>T26</th>\n",
       "      <th>T27</th>\n",
       "      <th>T28</th>\n",
       "      <th>T29</th>\n",
       "      <th>T30</th>\n",
       "      <th>T31</th>\n",
       "      <th>T32</th>\n",
       "      <th>T33</th>\n",
       "      <th>T34</th>\n",
       "      <th>T35</th>\n",
       "      <th>T36</th>\n",
       "      <th>T37</th>\n",
       "      <th>T38</th>\n",
       "      <th>T39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>562.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T0     T1    T2     T3    T4     T5     T6     T7     T8     T9  \\\n",
       "0      13.0    0.0   0.0   38.0   0.0    0.0    0.0   48.0   40.0    0.0   \n",
       "1       7.0   25.0   6.0    1.0  10.0   16.0    4.0    2.0    0.0    1.0   \n",
       "2      71.0   96.0   3.0  117.0  83.0  218.0  303.0    1.0   18.0   23.0   \n",
       "3     117.0   21.0  36.0    3.0   1.0   24.0  120.0    0.0   50.0   54.0   \n",
       "4       2.0    1.0   0.0    8.0   0.0    0.0    4.0    0.0    0.0    0.0   \n",
       "...     ...    ...   ...    ...   ...    ...    ...    ...    ...    ...   \n",
       "5336   64.0   28.0  29.0   21.0   9.0   25.0    0.0   42.0    3.0    0.0   \n",
       "5337   32.0   14.0   7.0   38.0  15.0   84.0   43.0   32.0    0.0    0.0   \n",
       "5338  562.0  272.0  62.0  149.0  73.0  265.0  142.0  107.0  279.0  197.0   \n",
       "5339    0.0   14.0   0.0   13.0   0.0    0.0   29.0    0.0    0.0    0.0   \n",
       "5340    0.0    1.0  21.0   31.0  48.0    0.0   10.0   49.0   33.0    0.0   \n",
       "\n",
       "        T10    T11    T12   T13    T14    T15    T16    T17   T18    T19  \\\n",
       "0       0.0   14.0    0.0   0.0  126.0    0.0    0.0    0.0   0.0   63.0   \n",
       "1       5.0    0.0    0.0   1.0   12.0   14.0   45.0   23.0  40.0   13.0   \n",
       "2       5.0    0.0    4.0  10.0  112.0    0.0    4.0   23.0   0.0   86.0   \n",
       "3       0.0   23.0   47.0  35.0  106.0   91.0   35.0   12.0  73.0   12.0   \n",
       "4       0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0   0.0    0.0   \n",
       "...     ...    ...    ...   ...    ...    ...    ...    ...   ...    ...   \n",
       "5336   25.0    0.0   34.0  16.0   35.0   21.0   15.0    1.0   6.0   41.0   \n",
       "5337   15.0    1.0    2.0  63.0    0.0   15.0    3.0   16.0   4.0    3.0   \n",
       "5338  217.0  195.0  179.0  68.0  221.0  134.0  278.0  207.0  55.0   68.0   \n",
       "5339    0.0    3.0   67.0   5.0    0.0    1.0    0.0    0.0   0.0    0.0   \n",
       "5340    0.0   40.0   20.0  17.0  161.0   78.0    0.0    6.0  48.0  173.0   \n",
       "\n",
       "        T20    T21    T22    T23    T24   T25    T26    T27    T28   T29  \\\n",
       "0       4.0    0.0    0.0    0.0  118.0   0.0    6.0    3.0    0.0   0.0   \n",
       "1       0.0    0.0    0.0   14.0    0.0   0.0    0.0    0.0    2.0  60.0   \n",
       "2       1.0  125.0   46.0   53.0    0.0  15.0   40.0   33.0   17.0  72.0   \n",
       "3     204.0   92.0  102.0   23.0   71.0  99.0   12.0  225.0  149.0   4.0   \n",
       "4       0.0    1.0    0.0    0.0    0.0   0.0    0.0    0.0    0.0   0.0   \n",
       "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...   \n",
       "5336    0.0    0.0   14.0    0.0   21.0  15.0   31.0    0.0    2.0  14.0   \n",
       "5337    8.0    4.0   17.0   14.0   42.0   2.0    0.0   14.0    1.0   1.0   \n",
       "5338   55.0   40.0  211.0  251.0   72.0  34.0   29.0  129.0   64.0  21.0   \n",
       "5339    9.0    0.0    0.0   50.0    0.0   0.0   14.0    0.0    8.0   5.0   \n",
       "5340   44.0   32.0   60.0  143.0  131.0  38.0  114.0   95.0   88.0  26.0   \n",
       "\n",
       "        T30   T31   T32    T33   T34    T35   T36  T37  T38  T39  \n",
       "0     149.0   0.0   0.0    0.0  83.0   33.0   0.0  0.0  1.0  0.0  \n",
       "1       0.0   0.0   0.0    0.0   0.0    0.0   0.0  0.0  0.0  0.0  \n",
       "2      35.0   0.0   0.0    0.0  59.0    3.0   3.0  5.0  4.0  0.0  \n",
       "3      19.0  17.0  67.0    0.0  54.0    0.0   0.0  0.0  0.0  0.0  \n",
       "4       0.0   0.0   0.0    0.0   0.0    0.0   0.0  0.0  0.0  0.0  \n",
       "...     ...   ...   ...    ...   ...    ...   ...  ...  ...  ...  \n",
       "5336   30.0   1.0   8.0   78.0   0.0    2.0   0.0  0.0  0.0  0.0  \n",
       "5337    7.0   0.0   0.0   56.0   0.0    0.0   0.0  0.0  0.0  0.0  \n",
       "5338    0.0  44.0  48.0  103.0   4.0    7.0   0.0  0.0  0.0  0.0  \n",
       "5339    4.0  31.0  11.0    1.0   0.0    0.0   0.0  0.0  0.0  0.0  \n",
       "5340   84.0  58.0  16.0   46.0  85.0  160.0  22.0  9.0  6.0  0.0  \n",
       "\n",
       "[5341 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['final_result','id1'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUii8R-ni9fx",
    "outputId": "e7e0ebd7-fd92-4508-e22c-6e5677c2c567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "5336    1\n",
       "5337    0\n",
       "5338    1\n",
       "5339    0\n",
       "5340    1\n",
       "Name: final_result, Length: 5341, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['final_result']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cc1lzGR3nWCp"
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Pn6SWVzmxSK",
    "outputId": "999516d8-25c3-48db-a1a0-92a2395b511c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zdp48uyacHvh"
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3738, 40)\n",
      "(1603, 40)\n",
      "(3738,)\n",
      "(1603,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train1)\n",
    "X_test = min_max_scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "epochs=200\n",
    "lr=0.0001\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  loss: 0.3198 - accuracy: 0.8871 (epochs=200, lr=0.0001)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: 0.4489 - accuracy: 0.7966 (epochs=100, lr=0.00001)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: 0.3110 - accuracy: 0.8877 (epochs=100, lr=0.0001) --> best\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: 0.4671 - accuracy: 0.8690 (epochs=100, lr=0.001)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 100)               4100      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 40)                4040      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 40)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,181\n",
      "Trainable params: 8,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5899 - val_loss: 0.6529 - val_accuracy: 0.7024\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.6360 - accuracy: 0.7025 - val_loss: 0.5982 - val_accuracy: 0.7024\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.5845 - accuracy: 0.7025 - val_loss: 0.5472 - val_accuracy: 0.7024\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.5502 - accuracy: 0.7025 - val_loss: 0.5217 - val_accuracy: 0.7024\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.5295 - accuracy: 0.7025 - val_loss: 0.5068 - val_accuracy: 0.7024\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.5165 - accuracy: 0.7025 - val_loss: 0.4928 - val_accuracy: 0.7024\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.5042 - accuracy: 0.7025 - val_loss: 0.4796 - val_accuracy: 0.7024\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.4920 - accuracy: 0.7030 - val_loss: 0.4656 - val_accuracy: 0.7024\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.4787 - accuracy: 0.7236 - val_loss: 0.4533 - val_accuracy: 0.7492\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.4712 - accuracy: 0.7790 - val_loss: 0.4437 - val_accuracy: 0.8091\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.4634 - accuracy: 0.8253 - val_loss: 0.4356 - val_accuracy: 0.8341\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.4581 - accuracy: 0.8451 - val_loss: 0.4271 - val_accuracy: 0.8546\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.4493 - accuracy: 0.8550 - val_loss: 0.4193 - val_accuracy: 0.8628\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4431 - accuracy: 0.8620 - val_loss: 0.4107 - val_accuracy: 0.8746\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 891us/step - loss: 0.4349 - accuracy: 0.8625 - val_loss: 0.4038 - val_accuracy: 0.8777\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4285 - accuracy: 0.8644 - val_loss: 0.3972 - val_accuracy: 0.8771\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.4255 - accuracy: 0.8596 - val_loss: 0.3927 - val_accuracy: 0.8802\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.4191 - accuracy: 0.8652 - val_loss: 0.3871 - val_accuracy: 0.8752\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 866us/step - loss: 0.4132 - accuracy: 0.8625 - val_loss: 0.3833 - val_accuracy: 0.8765\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.4072 - accuracy: 0.8676 - val_loss: 0.3782 - val_accuracy: 0.8696\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.4028 - accuracy: 0.8622 - val_loss: 0.3748 - val_accuracy: 0.8727\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 874us/step - loss: 0.4027 - accuracy: 0.8660 - val_loss: 0.3712 - val_accuracy: 0.8684\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3988 - accuracy: 0.8657 - val_loss: 0.3685 - val_accuracy: 0.8727\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 874us/step - loss: 0.3952 - accuracy: 0.8670 - val_loss: 0.3653 - val_accuracy: 0.8702\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 863us/step - loss: 0.3911 - accuracy: 0.8630 - val_loss: 0.3625 - val_accuracy: 0.8709\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 879us/step - loss: 0.3893 - accuracy: 0.8654 - val_loss: 0.3600 - val_accuracy: 0.8727\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3819 - accuracy: 0.8657 - val_loss: 0.3575 - val_accuracy: 0.8740\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 865us/step - loss: 0.3833 - accuracy: 0.8652 - val_loss: 0.3553 - val_accuracy: 0.8740\n",
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3771 - accuracy: 0.8689 - val_loss: 0.3524 - val_accuracy: 0.8709\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3745 - accuracy: 0.8684 - val_loss: 0.3505 - val_accuracy: 0.8709\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 866us/step - loss: 0.3746 - accuracy: 0.8657 - val_loss: 0.3488 - val_accuracy: 0.8734\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3659 - accuracy: 0.8684 - val_loss: 0.3468 - val_accuracy: 0.8740\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3669 - accuracy: 0.8686 - val_loss: 0.3453 - val_accuracy: 0.8759\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3637 - accuracy: 0.8703 - val_loss: 0.3427 - val_accuracy: 0.8721\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3600 - accuracy: 0.8740 - val_loss: 0.3408 - val_accuracy: 0.8715\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3623 - accuracy: 0.8673 - val_loss: 0.3394 - val_accuracy: 0.8709\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3604 - accuracy: 0.8705 - val_loss: 0.3378 - val_accuracy: 0.8752\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3551 - accuracy: 0.8713 - val_loss: 0.3363 - val_accuracy: 0.8752\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.3539 - accuracy: 0.8676 - val_loss: 0.3350 - val_accuracy: 0.8759\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3527 - accuracy: 0.8708 - val_loss: 0.3339 - val_accuracy: 0.8759\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3523 - accuracy: 0.8713 - val_loss: 0.3320 - val_accuracy: 0.8765\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 879us/step - loss: 0.3500 - accuracy: 0.8686 - val_loss: 0.3310 - val_accuracy: 0.8759\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3475 - accuracy: 0.8756 - val_loss: 0.3308 - val_accuracy: 0.8815\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3469 - accuracy: 0.8748 - val_loss: 0.3289 - val_accuracy: 0.8759\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3459 - accuracy: 0.8711 - val_loss: 0.3280 - val_accuracy: 0.8765\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3388 - accuracy: 0.8759 - val_loss: 0.3270 - val_accuracy: 0.8777\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3430 - accuracy: 0.8756 - val_loss: 0.3259 - val_accuracy: 0.8784\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3401 - accuracy: 0.8767 - val_loss: 0.3250 - val_accuracy: 0.8771\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3371 - accuracy: 0.8783 - val_loss: 0.3241 - val_accuracy: 0.8765\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.3368 - accuracy: 0.8769 - val_loss: 0.3241 - val_accuracy: 0.8815\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3328 - accuracy: 0.8793 - val_loss: 0.3231 - val_accuracy: 0.8796\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3335 - accuracy: 0.8756 - val_loss: 0.3225 - val_accuracy: 0.8802\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3319 - accuracy: 0.8748 - val_loss: 0.3214 - val_accuracy: 0.8790\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3327 - accuracy: 0.8751 - val_loss: 0.3212 - val_accuracy: 0.8815\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3278 - accuracy: 0.8793 - val_loss: 0.3203 - val_accuracy: 0.8796\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3297 - accuracy: 0.8799 - val_loss: 0.3199 - val_accuracy: 0.8796\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 877us/step - loss: 0.3272 - accuracy: 0.8793 - val_loss: 0.3193 - val_accuracy: 0.8796\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3291 - accuracy: 0.8796 - val_loss: 0.3189 - val_accuracy: 0.8802\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3275 - accuracy: 0.8791 - val_loss: 0.3187 - val_accuracy: 0.8815\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3275 - accuracy: 0.8793 - val_loss: 0.3181 - val_accuracy: 0.8815\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3269 - accuracy: 0.8793 - val_loss: 0.3180 - val_accuracy: 0.8821\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3263 - accuracy: 0.8815 - val_loss: 0.3171 - val_accuracy: 0.8784\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3272 - accuracy: 0.8815 - val_loss: 0.3171 - val_accuracy: 0.8815\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3230 - accuracy: 0.8785 - val_loss: 0.3167 - val_accuracy: 0.8815\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3230 - accuracy: 0.8793 - val_loss: 0.3162 - val_accuracy: 0.8815\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3228 - accuracy: 0.8812 - val_loss: 0.3162 - val_accuracy: 0.8796\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 920us/step - loss: 0.3254 - accuracy: 0.8820 - val_loss: 0.3158 - val_accuracy: 0.8796\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 970us/step - loss: 0.3229 - accuracy: 0.8815 - val_loss: 0.3154 - val_accuracy: 0.8802\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 963us/step - loss: 0.3235 - accuracy: 0.8820 - val_loss: 0.3151 - val_accuracy: 0.8802\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3194 - accuracy: 0.8823 - val_loss: 0.3150 - val_accuracy: 0.8808\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 904us/step - loss: 0.3244 - accuracy: 0.8812 - val_loss: 0.3148 - val_accuracy: 0.8815\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3179 - accuracy: 0.8828 - val_loss: 0.3150 - val_accuracy: 0.8790\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3188 - accuracy: 0.8831 - val_loss: 0.3146 - val_accuracy: 0.8808\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3164 - accuracy: 0.8801 - val_loss: 0.3146 - val_accuracy: 0.8808\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 866us/step - loss: 0.3127 - accuracy: 0.8828 - val_loss: 0.3144 - val_accuracy: 0.8808\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3169 - accuracy: 0.8834 - val_loss: 0.3141 - val_accuracy: 0.8833\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3171 - accuracy: 0.8828 - val_loss: 0.3138 - val_accuracy: 0.8815\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 874us/step - loss: 0.3163 - accuracy: 0.8847 - val_loss: 0.3136 - val_accuracy: 0.8833\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3170 - accuracy: 0.8818 - val_loss: 0.3136 - val_accuracy: 0.8827\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8858 - val_loss: 0.3138 - val_accuracy: 0.8833\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 937us/step - loss: 0.3165 - accuracy: 0.8844 - val_loss: 0.3135 - val_accuracy: 0.8821\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 929us/step - loss: 0.3124 - accuracy: 0.8836 - val_loss: 0.3132 - val_accuracy: 0.8840\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3166 - accuracy: 0.8844 - val_loss: 0.3127 - val_accuracy: 0.8833\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3088 - accuracy: 0.8842 - val_loss: 0.3128 - val_accuracy: 0.8833\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3136 - accuracy: 0.8868 - val_loss: 0.3127 - val_accuracy: 0.8833\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3085 - accuracy: 0.8863 - val_loss: 0.3131 - val_accuracy: 0.8852\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3131 - accuracy: 0.8855 - val_loss: 0.3129 - val_accuracy: 0.8846\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3091 - accuracy: 0.8866 - val_loss: 0.3128 - val_accuracy: 0.8846\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3124 - accuracy: 0.8855 - val_loss: 0.3128 - val_accuracy: 0.8846\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3072 - accuracy: 0.8855 - val_loss: 0.3130 - val_accuracy: 0.8858\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3174 - accuracy: 0.8863 - val_loss: 0.3128 - val_accuracy: 0.8858\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3101 - accuracy: 0.8847 - val_loss: 0.3126 - val_accuracy: 0.8852\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.3128 - accuracy: 0.8847 - val_loss: 0.3126 - val_accuracy: 0.8858\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3096 - accuracy: 0.8858 - val_loss: 0.3127 - val_accuracy: 0.8858\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3069 - accuracy: 0.8858 - val_loss: 0.3142 - val_accuracy: 0.8808\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3073 - accuracy: 0.8868 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3113 - accuracy: 0.8879 - val_loss: 0.3124 - val_accuracy: 0.8865\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3093 - accuracy: 0.8890 - val_loss: 0.3128 - val_accuracy: 0.8846\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3084 - accuracy: 0.8876 - val_loss: 0.3122 - val_accuracy: 0.8858\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3060 - accuracy: 0.8884 - val_loss: 0.3126 - val_accuracy: 0.8871\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 865us/step - loss: 0.3122 - accuracy: 0.8860 - val_loss: 0.3124 - val_accuracy: 0.8865\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3075 - accuracy: 0.8884 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 103/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3039 - accuracy: 0.8884 - val_loss: 0.3125 - val_accuracy: 0.8865\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3030 - accuracy: 0.8866 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3085 - accuracy: 0.8876 - val_loss: 0.3128 - val_accuracy: 0.8858\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3075 - accuracy: 0.8887 - val_loss: 0.3126 - val_accuracy: 0.8865\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3055 - accuracy: 0.8895 - val_loss: 0.3123 - val_accuracy: 0.8858\n",
      "Epoch 108/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3047 - accuracy: 0.8884 - val_loss: 0.3122 - val_accuracy: 0.8883\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3042 - accuracy: 0.8866 - val_loss: 0.3122 - val_accuracy: 0.8865\n",
      "Epoch 110/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3002 - accuracy: 0.8909 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.3042 - accuracy: 0.8900 - val_loss: 0.3133 - val_accuracy: 0.8871\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3049 - accuracy: 0.8895 - val_loss: 0.3124 - val_accuracy: 0.8852\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 903us/step - loss: 0.3029 - accuracy: 0.8879 - val_loss: 0.3129 - val_accuracy: 0.8871\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3036 - accuracy: 0.8884 - val_loss: 0.3132 - val_accuracy: 0.8871\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3018 - accuracy: 0.8933 - val_loss: 0.3128 - val_accuracy: 0.8865\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3050 - accuracy: 0.8895 - val_loss: 0.3122 - val_accuracy: 0.8865\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3024 - accuracy: 0.8887 - val_loss: 0.3118 - val_accuracy: 0.8858\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3009 - accuracy: 0.8914 - val_loss: 0.3131 - val_accuracy: 0.8871\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3057 - accuracy: 0.8906 - val_loss: 0.3126 - val_accuracy: 0.8858\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3010 - accuracy: 0.8906 - val_loss: 0.3130 - val_accuracy: 0.8865\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3023 - accuracy: 0.8903 - val_loss: 0.3131 - val_accuracy: 0.8858\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3036 - accuracy: 0.8898 - val_loss: 0.3126 - val_accuracy: 0.8858\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3017 - accuracy: 0.8914 - val_loss: 0.3132 - val_accuracy: 0.8858\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2988 - accuracy: 0.8911 - val_loss: 0.3134 - val_accuracy: 0.8852\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2978 - accuracy: 0.8925 - val_loss: 0.3139 - val_accuracy: 0.8865\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2955 - accuracy: 0.8898 - val_loss: 0.3132 - val_accuracy: 0.8865\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2986 - accuracy: 0.8933 - val_loss: 0.3132 - val_accuracy: 0.8852\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2993 - accuracy: 0.8919 - val_loss: 0.3136 - val_accuracy: 0.8883\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.2971 - accuracy: 0.8919 - val_loss: 0.3136 - val_accuracy: 0.8865\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2983 - accuracy: 0.8922 - val_loss: 0.3130 - val_accuracy: 0.8871\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2963 - accuracy: 0.8919 - val_loss: 0.3132 - val_accuracy: 0.8871\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2965 - accuracy: 0.8951 - val_loss: 0.3135 - val_accuracy: 0.8865\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2960 - accuracy: 0.8933 - val_loss: 0.3135 - val_accuracy: 0.8883\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.2992 - accuracy: 0.8903 - val_loss: 0.3137 - val_accuracy: 0.8852\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2989 - accuracy: 0.8911 - val_loss: 0.3138 - val_accuracy: 0.8877\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2986 - accuracy: 0.8919 - val_loss: 0.3131 - val_accuracy: 0.8865\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 859us/step - loss: 0.2965 - accuracy: 0.8933 - val_loss: 0.3135 - val_accuracy: 0.8865\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2934 - accuracy: 0.8900 - val_loss: 0.3144 - val_accuracy: 0.8877\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2952 - accuracy: 0.8919 - val_loss: 0.3139 - val_accuracy: 0.8890\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2907 - accuracy: 0.8925 - val_loss: 0.3145 - val_accuracy: 0.8883\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2965 - accuracy: 0.8919 - val_loss: 0.3140 - val_accuracy: 0.8858\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2978 - accuracy: 0.8906 - val_loss: 0.3139 - val_accuracy: 0.8865\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 873us/step - loss: 0.2911 - accuracy: 0.8943 - val_loss: 0.3143 - val_accuracy: 0.8871\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.2918 - accuracy: 0.8930 - val_loss: 0.3141 - val_accuracy: 0.8871\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.2944 - accuracy: 0.8938 - val_loss: 0.3139 - val_accuracy: 0.8865\n",
      "Epoch 146/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2931 - accuracy: 0.8957 - val_loss: 0.3143 - val_accuracy: 0.8858\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2953 - accuracy: 0.8925 - val_loss: 0.3146 - val_accuracy: 0.8871\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.2945 - accuracy: 0.8935 - val_loss: 0.3136 - val_accuracy: 0.8865\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2931 - accuracy: 0.8935 - val_loss: 0.3145 - val_accuracy: 0.8877\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2973 - accuracy: 0.8919 - val_loss: 0.3149 - val_accuracy: 0.8877\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.2916 - accuracy: 0.8917 - val_loss: 0.3146 - val_accuracy: 0.8877\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2955 - accuracy: 0.8911 - val_loss: 0.3145 - val_accuracy: 0.8858\n",
      "Epoch 153/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2915 - accuracy: 0.8909 - val_loss: 0.3151 - val_accuracy: 0.8871\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2924 - accuracy: 0.8951 - val_loss: 0.3146 - val_accuracy: 0.8871\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2909 - accuracy: 0.8943 - val_loss: 0.3153 - val_accuracy: 0.8865\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2893 - accuracy: 0.8933 - val_loss: 0.3158 - val_accuracy: 0.8871\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.2911 - accuracy: 0.8938 - val_loss: 0.3154 - val_accuracy: 0.8858\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.2900 - accuracy: 0.8943 - val_loss: 0.3155 - val_accuracy: 0.8858\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2909 - accuracy: 0.8951 - val_loss: 0.3155 - val_accuracy: 0.8865\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.2916 - accuracy: 0.8951 - val_loss: 0.3158 - val_accuracy: 0.8858\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.2902 - accuracy: 0.8951 - val_loss: 0.3164 - val_accuracy: 0.8871\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.2882 - accuracy: 0.8943 - val_loss: 0.3160 - val_accuracy: 0.8871\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 911us/step - loss: 0.2894 - accuracy: 0.8946 - val_loss: 0.3161 - val_accuracy: 0.8865\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.2897 - accuracy: 0.8949 - val_loss: 0.3158 - val_accuracy: 0.8871\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2927 - accuracy: 0.8933 - val_loss: 0.3160 - val_accuracy: 0.8877\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2908 - accuracy: 0.8949 - val_loss: 0.3160 - val_accuracy: 0.8877\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.2928 - accuracy: 0.8957 - val_loss: 0.3162 - val_accuracy: 0.8858\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2893 - accuracy: 0.8930 - val_loss: 0.3167 - val_accuracy: 0.8871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.2855 - accuracy: 0.8962 - val_loss: 0.3176 - val_accuracy: 0.8877\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2885 - accuracy: 0.8933 - val_loss: 0.3176 - val_accuracy: 0.8877\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 892us/step - loss: 0.2892 - accuracy: 0.8933 - val_loss: 0.3170 - val_accuracy: 0.8883\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2916 - accuracy: 0.8951 - val_loss: 0.3162 - val_accuracy: 0.8877\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2911 - accuracy: 0.8959 - val_loss: 0.3161 - val_accuracy: 0.8865\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 866us/step - loss: 0.2877 - accuracy: 0.8957 - val_loss: 0.3167 - val_accuracy: 0.8865\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 843us/step - loss: 0.2877 - accuracy: 0.8959 - val_loss: 0.3170 - val_accuracy: 0.8877\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2888 - accuracy: 0.8965 - val_loss: 0.3175 - val_accuracy: 0.8877\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2865 - accuracy: 0.8946 - val_loss: 0.3182 - val_accuracy: 0.8871\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.2896 - accuracy: 0.8925 - val_loss: 0.3175 - val_accuracy: 0.8871\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2878 - accuracy: 0.8951 - val_loss: 0.3185 - val_accuracy: 0.8871\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.2912 - accuracy: 0.8951 - val_loss: 0.3182 - val_accuracy: 0.8865\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2868 - accuracy: 0.8954 - val_loss: 0.3175 - val_accuracy: 0.8877\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2875 - accuracy: 0.8946 - val_loss: 0.3173 - val_accuracy: 0.8865\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 851us/step - loss: 0.2841 - accuracy: 0.8949 - val_loss: 0.3174 - val_accuracy: 0.8865\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.2873 - accuracy: 0.8943 - val_loss: 0.3185 - val_accuracy: 0.8871\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2875 - accuracy: 0.8949 - val_loss: 0.3182 - val_accuracy: 0.8871\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 862us/step - loss: 0.2849 - accuracy: 0.8965 - val_loss: 0.3186 - val_accuracy: 0.8865\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 854us/step - loss: 0.2855 - accuracy: 0.8970 - val_loss: 0.3184 - val_accuracy: 0.8877\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2839 - accuracy: 0.8962 - val_loss: 0.3178 - val_accuracy: 0.8877\n",
      "Epoch 189/200\n",
      "117/117 [==============================] - 0s 851us/step - loss: 0.2804 - accuracy: 0.8986 - val_loss: 0.3185 - val_accuracy: 0.8877\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2864 - accuracy: 0.8965 - val_loss: 0.3179 - val_accuracy: 0.8865\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 850us/step - loss: 0.2818 - accuracy: 0.8978 - val_loss: 0.3182 - val_accuracy: 0.8871\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 855us/step - loss: 0.2846 - accuracy: 0.8965 - val_loss: 0.3177 - val_accuracy: 0.8865\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 851us/step - loss: 0.2853 - accuracy: 0.8981 - val_loss: 0.3180 - val_accuracy: 0.8877\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 860us/step - loss: 0.2845 - accuracy: 0.8975 - val_loss: 0.3185 - val_accuracy: 0.8871\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 865us/step - loss: 0.2844 - accuracy: 0.8951 - val_loss: 0.3187 - val_accuracy: 0.8877\n",
      "Epoch 196/200\n",
      "117/117 [==============================] - 0s 869us/step - loss: 0.2841 - accuracy: 0.8970 - val_loss: 0.3183 - val_accuracy: 0.8883\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 868us/step - loss: 0.2860 - accuracy: 0.8981 - val_loss: 0.3185 - val_accuracy: 0.8871\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.2865 - accuracy: 0.8970 - val_loss: 0.3181 - val_accuracy: 0.8871\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 859us/step - loss: 0.2850 - accuracy: 0.8989 - val_loss: 0.3188 - val_accuracy: 0.8883\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 865us/step - loss: 0.2833 - accuracy: 0.8962 - val_loss: 0.3198 - val_accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "history_model = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 200, 'steps': 117}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 419us/step - loss: 0.3198 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31979358196258545, 0.8870866894721985]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot MLP learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_model.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to plot\n",
    "\n",
    "def validation_training_process(history):\n",
    "  plt.plot(history.history['loss'], label='Training Loss', color='green', linestyle = '--')\n",
    "  plt.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle ='--')\n",
    "  plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
    "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue')\n",
    "  plt.title('Training Process Visualization')\n",
    "\n",
    "  plt.xlabel('No. epoch')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_training_process(history_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_onlineCode_BBB_planB_monthly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "student_prediction",
   "language": "python",
   "name": "student_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
