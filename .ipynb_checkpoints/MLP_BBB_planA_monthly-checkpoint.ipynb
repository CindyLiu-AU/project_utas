{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D, Dropout, Activation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VvXOu32XOMIz"
   },
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv('BBB_planA_monthly.csv')\n",
    "df = df_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>id1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>117.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>1</td>\n",
       "      <td>562.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      final_result     T0     T1     T2     T3     T4     T5     T6     T7  \\\n",
       "0                1   13.0   38.0   88.0   14.0  126.0   67.0  124.0  152.0   \n",
       "1                1    7.0   42.0   22.0    7.0  101.0   46.0   14.0   62.0   \n",
       "2                0   71.0  333.0  510.0   38.0  139.0  247.0  119.0  157.0   \n",
       "3                1  117.0   72.0  211.0  131.0  244.0  483.0  193.0  409.0   \n",
       "4                0    2.0    9.0    4.0    0.0    0.0    1.0    0.0    0.0   \n",
       "...            ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5336             1   64.0   95.0   62.0   74.0   73.0   48.0   56.0   70.0   \n",
       "5337             0   32.0   74.0  159.0   81.0   38.0   15.0   75.0   23.0   \n",
       "5338             1  562.0  675.0  770.0  756.0  856.0  374.0  425.0  218.0   \n",
       "5339             0    0.0   27.0   29.0   75.0    1.0    9.0   64.0   17.0   \n",
       "5340             1    0.0  101.0   92.0   77.0  263.0  287.0  444.0  327.0   \n",
       "\n",
       "         T8    T9   id1  \n",
       "0      83.0  34.0     0  \n",
       "1       0.0   0.0     1  \n",
       "2      62.0  12.0     2  \n",
       "3     138.0   0.0     3  \n",
       "4       0.0   0.0     4  \n",
       "...     ...   ...   ...  \n",
       "5336   89.0   0.0  5336  \n",
       "5337   56.0   0.0  5337  \n",
       "5338  206.0   0.0  5338  \n",
       "5339   43.0   0.0  5339  \n",
       "5340  309.0  93.0  5340  \n",
       "\n",
       "[5341 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "xS2B1k_Pich7",
    "outputId": "af18988d-e764-4505-9dbe-af7cf825edae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>64.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>562.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T0     T1     T2     T3     T4     T5     T6     T7     T8    T9\n",
       "0      13.0   38.0   88.0   14.0  126.0   67.0  124.0  152.0   83.0  34.0\n",
       "1       7.0   42.0   22.0    7.0  101.0   46.0   14.0   62.0    0.0   0.0\n",
       "2      71.0  333.0  510.0   38.0  139.0  247.0  119.0  157.0   62.0  12.0\n",
       "3     117.0   72.0  211.0  131.0  244.0  483.0  193.0  409.0  138.0   0.0\n",
       "4       2.0    9.0    4.0    0.0    0.0    1.0    0.0    0.0    0.0   0.0\n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...   ...\n",
       "5336   64.0   95.0   62.0   74.0   73.0   48.0   56.0   70.0   89.0   0.0\n",
       "5337   32.0   74.0  159.0   81.0   38.0   15.0   75.0   23.0   56.0   0.0\n",
       "5338  562.0  675.0  770.0  756.0  856.0  374.0  425.0  218.0  206.0   0.0\n",
       "5339    0.0   27.0   29.0   75.0    1.0    9.0   64.0   17.0   43.0   0.0\n",
       "5340    0.0  101.0   92.0   77.0  263.0  287.0  444.0  327.0  309.0  93.0\n",
       "\n",
       "[5341 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['final_result','id1'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUii8R-ni9fx",
    "outputId": "e7e0ebd7-fd92-4508-e22c-6e5677c2c567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "5336    1\n",
       "5337    0\n",
       "5338    1\n",
       "5339    0\n",
       "5340    1\n",
       "Name: final_result, Length: 5341, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['final_result']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cc1lzGR3nWCp"
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Pn6SWVzmxSK",
    "outputId": "999516d8-25c3-48db-a1a0-92a2395b511c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zdp48uyacHvh"
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3738, 10)\n",
      "(1603, 10)\n",
      "(3738,)\n",
      "(1603,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train1)\n",
    "X_test = min_max_scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "epochs=200\n",
    "lr=0.0001\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(70, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: 0.2991 - accuracy: 0.8896 (epochs=200, lr=0.0001)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(70, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: 0.3024 - accuracy: 0.8927 (epochs=100, lr=0.0001) --> best\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(70, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 100)               1100      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 70)                7070      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 70)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,241\n",
      "Trainable params: 8,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.7022 - val_loss: 0.6294 - val_accuracy: 0.7024\n",
      "Epoch 2/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.6131 - accuracy: 0.7025 - val_loss: 0.5749 - val_accuracy: 0.7024\n",
      "Epoch 3/200\n",
      "117/117 [==============================] - 0s 893us/step - loss: 0.5716 - accuracy: 0.7025 - val_loss: 0.5446 - val_accuracy: 0.7024\n",
      "Epoch 4/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.5524 - accuracy: 0.7025 - val_loss: 0.5276 - val_accuracy: 0.7024\n",
      "Epoch 5/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.5361 - accuracy: 0.7025 - val_loss: 0.5113 - val_accuracy: 0.7024\n",
      "Epoch 6/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.5209 - accuracy: 0.7025 - val_loss: 0.4945 - val_accuracy: 0.7024\n",
      "Epoch 7/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.5066 - accuracy: 0.7025 - val_loss: 0.4796 - val_accuracy: 0.7024\n",
      "Epoch 8/200\n",
      "117/117 [==============================] - 0s 897us/step - loss: 0.4957 - accuracy: 0.7119 - val_loss: 0.4644 - val_accuracy: 0.7031\n",
      "Epoch 9/200\n",
      "117/117 [==============================] - 0s 898us/step - loss: 0.4847 - accuracy: 0.7541 - val_loss: 0.4526 - val_accuracy: 0.7916\n",
      "Epoch 10/200\n",
      "117/117 [==============================] - 0s 929us/step - loss: 0.4745 - accuracy: 0.7943 - val_loss: 0.4428 - val_accuracy: 0.8197\n",
      "Epoch 11/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4666 - accuracy: 0.8210 - val_loss: 0.4345 - val_accuracy: 0.8391\n",
      "Epoch 12/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4595 - accuracy: 0.8325 - val_loss: 0.4249 - val_accuracy: 0.8565\n",
      "Epoch 13/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4532 - accuracy: 0.8467 - val_loss: 0.4185 - val_accuracy: 0.8571\n",
      "Epoch 14/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.4473 - accuracy: 0.8470 - val_loss: 0.4115 - val_accuracy: 0.8640\n",
      "Epoch 15/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.4440 - accuracy: 0.8545 - val_loss: 0.4055 - val_accuracy: 0.8734\n",
      "Epoch 16/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.4383 - accuracy: 0.8537 - val_loss: 0.3997 - val_accuracy: 0.8734\n",
      "Epoch 17/200\n",
      "117/117 [==============================] - 0s 898us/step - loss: 0.4309 - accuracy: 0.8563 - val_loss: 0.3968 - val_accuracy: 0.8727\n",
      "Epoch 18/200\n",
      "117/117 [==============================] - 0s 985us/step - loss: 0.4307 - accuracy: 0.8545 - val_loss: 0.3908 - val_accuracy: 0.8777\n",
      "Epoch 19/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.4267 - accuracy: 0.8526 - val_loss: 0.3875 - val_accuracy: 0.8790\n",
      "Epoch 20/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.4209 - accuracy: 0.8582 - val_loss: 0.3819 - val_accuracy: 0.8765\n",
      "Epoch 21/200\n",
      "117/117 [==============================] - 0s 895us/step - loss: 0.4168 - accuracy: 0.8550 - val_loss: 0.3789 - val_accuracy: 0.8790\n",
      "Epoch 22/200\n",
      "117/117 [==============================] - 0s 892us/step - loss: 0.4150 - accuracy: 0.8480 - val_loss: 0.3751 - val_accuracy: 0.8808\n",
      "Epoch 23/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.4072 - accuracy: 0.8561 - val_loss: 0.3720 - val_accuracy: 0.8796\n",
      "Epoch 24/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.4076 - accuracy: 0.8593 - val_loss: 0.3689 - val_accuracy: 0.8808\n",
      "Epoch 25/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.4038 - accuracy: 0.8574 - val_loss: 0.3662 - val_accuracy: 0.8790\n",
      "Epoch 26/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3989 - accuracy: 0.8622 - val_loss: 0.3630 - val_accuracy: 0.8802\n",
      "Epoch 27/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3996 - accuracy: 0.8521 - val_loss: 0.3609 - val_accuracy: 0.8815\n",
      "Epoch 28/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3938 - accuracy: 0.8598 - val_loss: 0.3589 - val_accuracy: 0.8827\n",
      "Epoch 29/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3922 - accuracy: 0.8574 - val_loss: 0.3558 - val_accuracy: 0.8821\n",
      "Epoch 30/200\n",
      "117/117 [==============================] - 0s 927us/step - loss: 0.3899 - accuracy: 0.8606 - val_loss: 0.3531 - val_accuracy: 0.8808\n",
      "Epoch 31/200\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3887 - accuracy: 0.8609 - val_loss: 0.3520 - val_accuracy: 0.8840\n",
      "Epoch 32/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3824 - accuracy: 0.8636 - val_loss: 0.3488 - val_accuracy: 0.8821\n",
      "Epoch 33/200\n",
      "117/117 [==============================] - 0s 896us/step - loss: 0.3822 - accuracy: 0.8620 - val_loss: 0.3482 - val_accuracy: 0.8858\n",
      "Epoch 34/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3767 - accuracy: 0.8622 - val_loss: 0.3447 - val_accuracy: 0.8833\n",
      "Epoch 35/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.3746 - accuracy: 0.8633 - val_loss: 0.3420 - val_accuracy: 0.8808\n",
      "Epoch 36/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3762 - accuracy: 0.8625 - val_loss: 0.3405 - val_accuracy: 0.8833\n",
      "Epoch 37/200\n",
      "117/117 [==============================] - 0s 893us/step - loss: 0.3713 - accuracy: 0.8638 - val_loss: 0.3391 - val_accuracy: 0.8833\n",
      "Epoch 38/200\n",
      "117/117 [==============================] - 0s 895us/step - loss: 0.3706 - accuracy: 0.8657 - val_loss: 0.3373 - val_accuracy: 0.8827\n",
      "Epoch 39/200\n",
      "117/117 [==============================] - 0s 891us/step - loss: 0.3668 - accuracy: 0.8620 - val_loss: 0.3364 - val_accuracy: 0.8846\n",
      "Epoch 40/200\n",
      "117/117 [==============================] - 0s 899us/step - loss: 0.3671 - accuracy: 0.8670 - val_loss: 0.3346 - val_accuracy: 0.8833\n",
      "Epoch 41/200\n",
      "117/117 [==============================] - 0s 892us/step - loss: 0.3645 - accuracy: 0.8681 - val_loss: 0.3324 - val_accuracy: 0.8827\n",
      "Epoch 42/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3626 - accuracy: 0.8705 - val_loss: 0.3309 - val_accuracy: 0.8833\n",
      "Epoch 43/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3603 - accuracy: 0.8676 - val_loss: 0.3320 - val_accuracy: 0.8871\n",
      "Epoch 44/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3595 - accuracy: 0.8649 - val_loss: 0.3285 - val_accuracy: 0.8852\n",
      "Epoch 45/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3592 - accuracy: 0.8668 - val_loss: 0.3277 - val_accuracy: 0.8896\n",
      "Epoch 46/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.3590 - accuracy: 0.8705 - val_loss: 0.3260 - val_accuracy: 0.8865\n",
      "Epoch 47/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3557 - accuracy: 0.8705 - val_loss: 0.3247 - val_accuracy: 0.8865\n",
      "Epoch 48/200\n",
      "117/117 [==============================] - 0s 895us/step - loss: 0.3536 - accuracy: 0.8700 - val_loss: 0.3232 - val_accuracy: 0.8846\n",
      "Epoch 49/200\n",
      "117/117 [==============================] - 0s 897us/step - loss: 0.3525 - accuracy: 0.8716 - val_loss: 0.3220 - val_accuracy: 0.8852\n",
      "Epoch 50/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3517 - accuracy: 0.8700 - val_loss: 0.3231 - val_accuracy: 0.8865\n",
      "Epoch 51/200\n",
      "117/117 [==============================] - 0s 893us/step - loss: 0.3502 - accuracy: 0.8756 - val_loss: 0.3208 - val_accuracy: 0.8883\n",
      "Epoch 52/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3480 - accuracy: 0.8708 - val_loss: 0.3218 - val_accuracy: 0.8871\n",
      "Epoch 53/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.3478 - accuracy: 0.8724 - val_loss: 0.3189 - val_accuracy: 0.8896\n",
      "Epoch 54/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3483 - accuracy: 0.8737 - val_loss: 0.3187 - val_accuracy: 0.8865\n",
      "Epoch 55/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3442 - accuracy: 0.8745 - val_loss: 0.3178 - val_accuracy: 0.8865\n",
      "Epoch 56/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3419 - accuracy: 0.8751 - val_loss: 0.3166 - val_accuracy: 0.8877\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 902us/step - loss: 0.3415 - accuracy: 0.8769 - val_loss: 0.3160 - val_accuracy: 0.8877\n",
      "Epoch 58/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3451 - accuracy: 0.8769 - val_loss: 0.3153 - val_accuracy: 0.8871\n",
      "Epoch 59/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3394 - accuracy: 0.8788 - val_loss: 0.3152 - val_accuracy: 0.8877\n",
      "Epoch 60/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3415 - accuracy: 0.8740 - val_loss: 0.3142 - val_accuracy: 0.8871\n",
      "Epoch 61/200\n",
      "117/117 [==============================] - 0s 896us/step - loss: 0.3399 - accuracy: 0.8783 - val_loss: 0.3148 - val_accuracy: 0.8871\n",
      "Epoch 62/200\n",
      "117/117 [==============================] - 0s 898us/step - loss: 0.3400 - accuracy: 0.8818 - val_loss: 0.3126 - val_accuracy: 0.8871\n",
      "Epoch 63/200\n",
      "117/117 [==============================] - 0s 900us/step - loss: 0.3380 - accuracy: 0.8737 - val_loss: 0.3126 - val_accuracy: 0.8865\n",
      "Epoch 64/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3357 - accuracy: 0.8780 - val_loss: 0.3129 - val_accuracy: 0.8877\n",
      "Epoch 65/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3366 - accuracy: 0.8823 - val_loss: 0.3116 - val_accuracy: 0.8858\n",
      "Epoch 66/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3312 - accuracy: 0.8777 - val_loss: 0.3100 - val_accuracy: 0.8865\n",
      "Epoch 67/200\n",
      "117/117 [==============================] - 0s 873us/step - loss: 0.3360 - accuracy: 0.8793 - val_loss: 0.3100 - val_accuracy: 0.8871\n",
      "Epoch 68/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3356 - accuracy: 0.8791 - val_loss: 0.3096 - val_accuracy: 0.8871\n",
      "Epoch 69/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3344 - accuracy: 0.8772 - val_loss: 0.3089 - val_accuracy: 0.8871\n",
      "Epoch 70/200\n",
      "117/117 [==============================] - 0s 895us/step - loss: 0.3325 - accuracy: 0.8788 - val_loss: 0.3090 - val_accuracy: 0.8865\n",
      "Epoch 71/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.3304 - accuracy: 0.8804 - val_loss: 0.3083 - val_accuracy: 0.8852\n",
      "Epoch 72/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3329 - accuracy: 0.8799 - val_loss: 0.3075 - val_accuracy: 0.8877\n",
      "Epoch 73/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3311 - accuracy: 0.8799 - val_loss: 0.3070 - val_accuracy: 0.8865\n",
      "Epoch 74/200\n",
      "117/117 [==============================] - 0s 879us/step - loss: 0.3308 - accuracy: 0.8799 - val_loss: 0.3072 - val_accuracy: 0.8865\n",
      "Epoch 75/200\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3307 - accuracy: 0.8793 - val_loss: 0.3068 - val_accuracy: 0.8871\n",
      "Epoch 76/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3318 - accuracy: 0.8796 - val_loss: 0.3086 - val_accuracy: 0.8902\n",
      "Epoch 77/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3289 - accuracy: 0.8799 - val_loss: 0.3065 - val_accuracy: 0.8896\n",
      "Epoch 78/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3270 - accuracy: 0.8820 - val_loss: 0.3069 - val_accuracy: 0.8902\n",
      "Epoch 79/200\n",
      "117/117 [==============================] - 0s 898us/step - loss: 0.3311 - accuracy: 0.8820 - val_loss: 0.3058 - val_accuracy: 0.8902\n",
      "Epoch 80/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3266 - accuracy: 0.8823 - val_loss: 0.3058 - val_accuracy: 0.8902\n",
      "Epoch 81/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3270 - accuracy: 0.8844 - val_loss: 0.3046 - val_accuracy: 0.8871\n",
      "Epoch 82/200\n",
      "117/117 [==============================] - 0s 899us/step - loss: 0.3258 - accuracy: 0.8847 - val_loss: 0.3049 - val_accuracy: 0.8908\n",
      "Epoch 83/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3260 - accuracy: 0.8801 - val_loss: 0.3043 - val_accuracy: 0.8896\n",
      "Epoch 84/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3246 - accuracy: 0.8823 - val_loss: 0.3059 - val_accuracy: 0.8896\n",
      "Epoch 85/200\n",
      "117/117 [==============================] - 0s 892us/step - loss: 0.3238 - accuracy: 0.8826 - val_loss: 0.3042 - val_accuracy: 0.8915\n",
      "Epoch 86/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3272 - accuracy: 0.8820 - val_loss: 0.3063 - val_accuracy: 0.8883\n",
      "Epoch 87/200\n",
      "117/117 [==============================] - 0s 911us/step - loss: 0.3243 - accuracy: 0.8831 - val_loss: 0.3044 - val_accuracy: 0.8902\n",
      "Epoch 88/200\n",
      "117/117 [==============================] - 0s 896us/step - loss: 0.3237 - accuracy: 0.8852 - val_loss: 0.3039 - val_accuracy: 0.8908\n",
      "Epoch 89/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3197 - accuracy: 0.8858 - val_loss: 0.3030 - val_accuracy: 0.8865\n",
      "Epoch 90/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3230 - accuracy: 0.8826 - val_loss: 0.3047 - val_accuracy: 0.8908\n",
      "Epoch 91/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3236 - accuracy: 0.8828 - val_loss: 0.3044 - val_accuracy: 0.8908\n",
      "Epoch 92/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3213 - accuracy: 0.8831 - val_loss: 0.3026 - val_accuracy: 0.8908\n",
      "Epoch 93/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3239 - accuracy: 0.8818 - val_loss: 0.3027 - val_accuracy: 0.8908\n",
      "Epoch 94/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3190 - accuracy: 0.8815 - val_loss: 0.3028 - val_accuracy: 0.8896\n",
      "Epoch 95/200\n",
      "117/117 [==============================] - 0s 919us/step - loss: 0.3190 - accuracy: 0.8836 - val_loss: 0.3026 - val_accuracy: 0.8852\n",
      "Epoch 96/200\n",
      "117/117 [==============================] - 0s 903us/step - loss: 0.3191 - accuracy: 0.8842 - val_loss: 0.3042 - val_accuracy: 0.8902\n",
      "Epoch 97/200\n",
      "117/117 [==============================] - 0s 901us/step - loss: 0.3205 - accuracy: 0.8834 - val_loss: 0.3033 - val_accuracy: 0.8908\n",
      "Epoch 98/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3220 - accuracy: 0.8860 - val_loss: 0.3018 - val_accuracy: 0.8908\n",
      "Epoch 99/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3179 - accuracy: 0.8847 - val_loss: 0.3029 - val_accuracy: 0.8902\n",
      "Epoch 100/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3180 - accuracy: 0.8836 - val_loss: 0.3035 - val_accuracy: 0.8902\n",
      "Epoch 101/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3200 - accuracy: 0.8844 - val_loss: 0.3018 - val_accuracy: 0.8896\n",
      "Epoch 102/200\n",
      "117/117 [==============================] - 0s 896us/step - loss: 0.3195 - accuracy: 0.8842 - val_loss: 0.3025 - val_accuracy: 0.8902\n",
      "Epoch 103/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3161 - accuracy: 0.8884 - val_loss: 0.3021 - val_accuracy: 0.8902\n",
      "Epoch 104/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.3165 - accuracy: 0.8871 - val_loss: 0.3018 - val_accuracy: 0.8908\n",
      "Epoch 105/200\n",
      "117/117 [==============================] - 0s 910us/step - loss: 0.3175 - accuracy: 0.8847 - val_loss: 0.3011 - val_accuracy: 0.8908\n",
      "Epoch 106/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3200 - accuracy: 0.8847 - val_loss: 0.3023 - val_accuracy: 0.8902\n",
      "Epoch 107/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3189 - accuracy: 0.8847 - val_loss: 0.3014 - val_accuracy: 0.8902\n",
      "Epoch 108/200\n",
      "117/117 [==============================] - 0s 902us/step - loss: 0.3172 - accuracy: 0.8858 - val_loss: 0.3026 - val_accuracy: 0.8921\n",
      "Epoch 109/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3184 - accuracy: 0.8855 - val_loss: 0.3027 - val_accuracy: 0.8902\n",
      "Epoch 110/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3174 - accuracy: 0.8860 - val_loss: 0.3022 - val_accuracy: 0.8902\n",
      "Epoch 111/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.3174 - accuracy: 0.8858 - val_loss: 0.3038 - val_accuracy: 0.8915\n",
      "Epoch 112/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3190 - accuracy: 0.8852 - val_loss: 0.3018 - val_accuracy: 0.8915\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 888us/step - loss: 0.3140 - accuracy: 0.8884 - val_loss: 0.3023 - val_accuracy: 0.8908\n",
      "Epoch 114/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3172 - accuracy: 0.8868 - val_loss: 0.3010 - val_accuracy: 0.8908\n",
      "Epoch 115/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3150 - accuracy: 0.8842 - val_loss: 0.3011 - val_accuracy: 0.8908\n",
      "Epoch 116/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3157 - accuracy: 0.8858 - val_loss: 0.3014 - val_accuracy: 0.8915\n",
      "Epoch 117/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3128 - accuracy: 0.8852 - val_loss: 0.3022 - val_accuracy: 0.8915\n",
      "Epoch 118/200\n",
      "117/117 [==============================] - 0s 887us/step - loss: 0.3159 - accuracy: 0.8874 - val_loss: 0.3014 - val_accuracy: 0.8915\n",
      "Epoch 119/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3153 - accuracy: 0.8847 - val_loss: 0.3021 - val_accuracy: 0.8915\n",
      "Epoch 120/200\n",
      "117/117 [==============================] - 0s 901us/step - loss: 0.3153 - accuracy: 0.8882 - val_loss: 0.3016 - val_accuracy: 0.8908\n",
      "Epoch 121/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.3012 - val_accuracy: 0.8915\n",
      "Epoch 122/200\n",
      "117/117 [==============================] - 0s 879us/step - loss: 0.3143 - accuracy: 0.8874 - val_loss: 0.3006 - val_accuracy: 0.8921\n",
      "Epoch 123/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.3144 - accuracy: 0.8858 - val_loss: 0.3007 - val_accuracy: 0.8921\n",
      "Epoch 124/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3150 - accuracy: 0.8863 - val_loss: 0.3004 - val_accuracy: 0.8908\n",
      "Epoch 125/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3112 - accuracy: 0.8874 - val_loss: 0.3007 - val_accuracy: 0.8915\n",
      "Epoch 126/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3144 - accuracy: 0.8871 - val_loss: 0.3013 - val_accuracy: 0.8915\n",
      "Epoch 127/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3126 - accuracy: 0.8855 - val_loss: 0.3010 - val_accuracy: 0.8915\n",
      "Epoch 128/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3141 - accuracy: 0.8866 - val_loss: 0.2999 - val_accuracy: 0.8908\n",
      "Epoch 129/200\n",
      "117/117 [==============================] - 0s 888us/step - loss: 0.3125 - accuracy: 0.8887 - val_loss: 0.3009 - val_accuracy: 0.8908\n",
      "Epoch 130/200\n",
      "117/117 [==============================] - 0s 879us/step - loss: 0.3141 - accuracy: 0.8858 - val_loss: 0.3002 - val_accuracy: 0.8908\n",
      "Epoch 131/200\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3131 - accuracy: 0.8866 - val_loss: 0.3005 - val_accuracy: 0.8915\n",
      "Epoch 132/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3112 - accuracy: 0.8882 - val_loss: 0.3008 - val_accuracy: 0.8915\n",
      "Epoch 133/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3125 - accuracy: 0.8860 - val_loss: 0.3007 - val_accuracy: 0.8908\n",
      "Epoch 134/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3115 - accuracy: 0.8892 - val_loss: 0.3006 - val_accuracy: 0.8915\n",
      "Epoch 135/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.3133 - accuracy: 0.8884 - val_loss: 0.2998 - val_accuracy: 0.8902\n",
      "Epoch 136/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3128 - accuracy: 0.8874 - val_loss: 0.3005 - val_accuracy: 0.8908\n",
      "Epoch 137/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3093 - accuracy: 0.8860 - val_loss: 0.3002 - val_accuracy: 0.8908\n",
      "Epoch 138/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3122 - accuracy: 0.8890 - val_loss: 0.3000 - val_accuracy: 0.8902\n",
      "Epoch 139/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3117 - accuracy: 0.8863 - val_loss: 0.2992 - val_accuracy: 0.8908\n",
      "Epoch 140/200\n",
      "117/117 [==============================] - 0s 900us/step - loss: 0.3105 - accuracy: 0.8882 - val_loss: 0.2998 - val_accuracy: 0.8902\n",
      "Epoch 141/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3084 - accuracy: 0.8858 - val_loss: 0.2999 - val_accuracy: 0.8896\n",
      "Epoch 142/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3108 - accuracy: 0.8863 - val_loss: 0.3000 - val_accuracy: 0.8915\n",
      "Epoch 143/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3108 - accuracy: 0.8887 - val_loss: 0.2999 - val_accuracy: 0.8908\n",
      "Epoch 144/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3090 - accuracy: 0.8884 - val_loss: 0.2997 - val_accuracy: 0.8896\n",
      "Epoch 145/200\n",
      "117/117 [==============================] - 0s 867us/step - loss: 0.3088 - accuracy: 0.8890 - val_loss: 0.3006 - val_accuracy: 0.8915\n",
      "Epoch 146/200\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3102 - accuracy: 0.8890 - val_loss: 0.3004 - val_accuracy: 0.8915\n",
      "Epoch 147/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3094 - accuracy: 0.8892 - val_loss: 0.2992 - val_accuracy: 0.8902\n",
      "Epoch 148/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3112 - accuracy: 0.8882 - val_loss: 0.3000 - val_accuracy: 0.8915\n",
      "Epoch 149/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3071 - accuracy: 0.8876 - val_loss: 0.2996 - val_accuracy: 0.8908\n",
      "Epoch 150/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3098 - accuracy: 0.8898 - val_loss: 0.3000 - val_accuracy: 0.8902\n",
      "Epoch 151/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3097 - accuracy: 0.8892 - val_loss: 0.2995 - val_accuracy: 0.8915\n",
      "Epoch 152/200\n",
      "117/117 [==============================] - 0s 894us/step - loss: 0.3069 - accuracy: 0.8895 - val_loss: 0.3000 - val_accuracy: 0.8908\n",
      "Epoch 153/200\n",
      "117/117 [==============================] - 0s 895us/step - loss: 0.3084 - accuracy: 0.8868 - val_loss: 0.3005 - val_accuracy: 0.8908\n",
      "Epoch 154/200\n",
      "117/117 [==============================] - 0s 892us/step - loss: 0.3078 - accuracy: 0.8898 - val_loss: 0.2999 - val_accuracy: 0.8908\n",
      "Epoch 155/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3095 - accuracy: 0.8895 - val_loss: 0.2991 - val_accuracy: 0.8902\n",
      "Epoch 156/200\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3101 - accuracy: 0.8876 - val_loss: 0.2987 - val_accuracy: 0.8902\n",
      "Epoch 157/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.3095 - accuracy: 0.8863 - val_loss: 0.2994 - val_accuracy: 0.8908\n",
      "Epoch 158/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3089 - accuracy: 0.8882 - val_loss: 0.2993 - val_accuracy: 0.8921\n",
      "Epoch 159/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3085 - accuracy: 0.8906 - val_loss: 0.3002 - val_accuracy: 0.8896\n",
      "Epoch 160/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3063 - accuracy: 0.8890 - val_loss: 0.2993 - val_accuracy: 0.8921\n",
      "Epoch 161/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3088 - accuracy: 0.8900 - val_loss: 0.2992 - val_accuracy: 0.8902\n",
      "Epoch 162/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3099 - accuracy: 0.8874 - val_loss: 0.3003 - val_accuracy: 0.8902\n",
      "Epoch 163/200\n",
      "117/117 [==============================] - 0s 870us/step - loss: 0.3056 - accuracy: 0.8892 - val_loss: 0.2993 - val_accuracy: 0.8915\n",
      "Epoch 164/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3094 - accuracy: 0.8895 - val_loss: 0.2988 - val_accuracy: 0.8908\n",
      "Epoch 165/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3064 - accuracy: 0.8879 - val_loss: 0.3003 - val_accuracy: 0.8902\n",
      "Epoch 166/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.3085 - accuracy: 0.8887 - val_loss: 0.3014 - val_accuracy: 0.8902\n",
      "Epoch 167/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3061 - accuracy: 0.8911 - val_loss: 0.2990 - val_accuracy: 0.8915\n",
      "Epoch 168/200\n",
      "117/117 [==============================] - 0s 865us/step - loss: 0.3057 - accuracy: 0.8892 - val_loss: 0.2991 - val_accuracy: 0.8915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3079 - accuracy: 0.8890 - val_loss: 0.2983 - val_accuracy: 0.8890\n",
      "Epoch 170/200\n",
      "117/117 [==============================] - 0s 884us/step - loss: 0.3057 - accuracy: 0.8903 - val_loss: 0.2985 - val_accuracy: 0.8915\n",
      "Epoch 171/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3039 - accuracy: 0.8882 - val_loss: 0.2986 - val_accuracy: 0.8908\n",
      "Epoch 172/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3058 - accuracy: 0.8858 - val_loss: 0.2990 - val_accuracy: 0.8908\n",
      "Epoch 173/200\n",
      "117/117 [==============================] - 0s 883us/step - loss: 0.3050 - accuracy: 0.8890 - val_loss: 0.3002 - val_accuracy: 0.8908\n",
      "Epoch 174/200\n",
      "117/117 [==============================] - 0s 886us/step - loss: 0.3055 - accuracy: 0.8914 - val_loss: 0.2987 - val_accuracy: 0.8908\n",
      "Epoch 175/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3054 - accuracy: 0.8903 - val_loss: 0.2994 - val_accuracy: 0.8921\n",
      "Epoch 176/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3068 - accuracy: 0.8919 - val_loss: 0.2992 - val_accuracy: 0.8915\n",
      "Epoch 177/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3068 - accuracy: 0.8898 - val_loss: 0.2988 - val_accuracy: 0.8890\n",
      "Epoch 178/200\n",
      "117/117 [==============================] - 0s 893us/step - loss: 0.3031 - accuracy: 0.8887 - val_loss: 0.3002 - val_accuracy: 0.8915\n",
      "Epoch 179/200\n",
      "117/117 [==============================] - 0s 890us/step - loss: 0.3060 - accuracy: 0.8892 - val_loss: 0.2988 - val_accuracy: 0.8908\n",
      "Epoch 180/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3038 - accuracy: 0.8906 - val_loss: 0.2982 - val_accuracy: 0.8890\n",
      "Epoch 181/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3045 - accuracy: 0.8906 - val_loss: 0.2996 - val_accuracy: 0.8915\n",
      "Epoch 182/200\n",
      "117/117 [==============================] - 0s 882us/step - loss: 0.3039 - accuracy: 0.8898 - val_loss: 0.2987 - val_accuracy: 0.8915\n",
      "Epoch 183/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3053 - accuracy: 0.8919 - val_loss: 0.3001 - val_accuracy: 0.8902\n",
      "Epoch 184/200\n",
      "117/117 [==============================] - 0s 889us/step - loss: 0.3041 - accuracy: 0.8919 - val_loss: 0.2987 - val_accuracy: 0.8896\n",
      "Epoch 185/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3046 - accuracy: 0.8909 - val_loss: 0.2993 - val_accuracy: 0.8915\n",
      "Epoch 186/200\n",
      "117/117 [==============================] - 0s 874us/step - loss: 0.3050 - accuracy: 0.8890 - val_loss: 0.2984 - val_accuracy: 0.8896\n",
      "Epoch 187/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3061 - accuracy: 0.8876 - val_loss: 0.2993 - val_accuracy: 0.8908\n",
      "Epoch 188/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3053 - accuracy: 0.8903 - val_loss: 0.2987 - val_accuracy: 0.8915\n",
      "Epoch 189/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3045 - accuracy: 0.8927 - val_loss: 0.2979 - val_accuracy: 0.8890\n",
      "Epoch 190/200\n",
      "117/117 [==============================] - 0s 880us/step - loss: 0.3019 - accuracy: 0.8922 - val_loss: 0.2999 - val_accuracy: 0.8915\n",
      "Epoch 191/200\n",
      "117/117 [==============================] - 0s 901us/step - loss: 0.3041 - accuracy: 0.8919 - val_loss: 0.2985 - val_accuracy: 0.8908\n",
      "Epoch 192/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3004 - accuracy: 0.8930 - val_loss: 0.2994 - val_accuracy: 0.8902\n",
      "Epoch 193/200\n",
      "117/117 [==============================] - 0s 877us/step - loss: 0.3041 - accuracy: 0.8879 - val_loss: 0.2986 - val_accuracy: 0.8902\n",
      "Epoch 194/200\n",
      "117/117 [==============================] - 0s 875us/step - loss: 0.3027 - accuracy: 0.8941 - val_loss: 0.2991 - val_accuracy: 0.8908\n",
      "Epoch 195/200\n",
      "117/117 [==============================] - 0s 885us/step - loss: 0.3045 - accuracy: 0.8909 - val_loss: 0.2984 - val_accuracy: 0.8896\n",
      "Epoch 196/200\n",
      "117/117 [==============================] - 0s 872us/step - loss: 0.3033 - accuracy: 0.8917 - val_loss: 0.2984 - val_accuracy: 0.8902\n",
      "Epoch 197/200\n",
      "117/117 [==============================] - 0s 881us/step - loss: 0.3001 - accuracy: 0.8890 - val_loss: 0.2990 - val_accuracy: 0.8896\n",
      "Epoch 198/200\n",
      "117/117 [==============================] - 0s 876us/step - loss: 0.3044 - accuracy: 0.8933 - val_loss: 0.2987 - val_accuracy: 0.8902\n",
      "Epoch 199/200\n",
      "117/117 [==============================] - 0s 871us/step - loss: 0.3034 - accuracy: 0.8892 - val_loss: 0.2999 - val_accuracy: 0.8896\n",
      "Epoch 200/200\n",
      "117/117 [==============================] - 0s 878us/step - loss: 0.3048 - accuracy: 0.8887 - val_loss: 0.2991 - val_accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "history_model = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 200, 'steps': 117}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 393us/step - loss: 0.2991 - accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29906970262527466, 0.8895820379257202]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot MLP learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_model.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to plot\n",
    "\n",
    "def validation_training_process(history):\n",
    "  plt.plot(history.history['loss'], label='Training Loss', color='green', linestyle = '--')\n",
    "  plt.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle ='--')\n",
    "  plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
    "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue')\n",
    "  plt.title('Training Process Visualization')\n",
    "\n",
    "  plt.xlabel('No. epoch')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_training_process(history_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_onlineCode_BBB_planB_monthly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "student_prediction",
   "language": "python",
   "name": "student_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
